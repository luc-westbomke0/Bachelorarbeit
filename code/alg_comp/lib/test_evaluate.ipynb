{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from torchinfo import summary\n",
    "# from contextlib import redirect_stdout\n",
    "\n",
    "# from model.fcae import createLevel5Net as createNet\n",
    "\n",
    "# from lib.evaluate import evaluate_total_predictions_set, display_mazes\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path_to_data = \"../data/\"\n",
    "\n",
    "data_size = (10, 10)\n",
    "\n",
    "# X_file = np.load(f\"{path_to_data}100000x{data_size[0]}x{data_size[1]}_unsolved.npy\")\n",
    "# Y_file = np.load(f\"{path_to_data}100000x{data_size[0]}x{data_size[1]}_solved.npy\")\n",
    "yHat_file = np.load(f\"{path_to_data}predicted_20000x{data_size[0]}x{data_size[1]}.npy\")\n",
    "y_file = np.load(f\"{path_to_data}label_20000x{data_size[0]}x{data_size[1]}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform to tensor\n",
    "# x_train = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "# y_train = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "\n",
    "yHat_test = torch.tensor(yHat_file, dtype=torch.float32, device=device)\n",
    "y_test = torch.tensor(y_file, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 1, 10, 10])\n",
      "torch.Size([20000, 1, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(yHat_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_found_path(answer: torch.Tensor, Y_test: torch.Tensor):\n",
    "    start = find_gate(answer, 0.6, True)\n",
    "    end = find_gate(answer, 0.6, False)\n",
    "\n",
    "    print(start, end)\n",
    "\n",
    "    if start is None or end is None:\n",
    "        return False\n",
    "\n",
    "    current = (start[0], start[1])\n",
    "    visited = set()\n",
    "    visited.add(current)\n",
    "\n",
    "    max_moves = (\n",
    "        answer.shape[0] * answer.shape[1]\n",
    "    )  # Consider the grid size for max moves\n",
    "    # max_moves = 17\n",
    "\n",
    "    for i in range(max_moves):\n",
    "        brightest_neighbour = find_brightest_neighbour(answer, current, visited, Y_test)\n",
    "        if brightest_neighbour is None:\n",
    "            return False\n",
    "        current = (brightest_neighbour[0], brightest_neighbour[1])\n",
    "        visited.add(current)\n",
    "        if current == end:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def find_gate(answer: torch.Tensor, threshold: float, start: bool):\n",
    "    rows, cols = answer.shape\n",
    "    gate_candidates = (answer >= threshold).nonzero(as_tuple=True)  # Finde alle Positionen über dem Threshold\n",
    "\n",
    "    if len(gate_candidates[0]) == 0:  # Kein Gate gefunden\n",
    "        return None\n",
    "\n",
    "    if start:\n",
    "        return gate_candidates[0][0].item(), gate_candidates[1][0].item()  # Erster gefundener Kandidat\n",
    "    else:\n",
    "        return gate_candidates[0][-1].item(), gate_candidates[1][-1].item()  # Letzter gefundener Kandidat\n",
    "\n",
    "def find_brightest_neighbour(\n",
    "    answer: torch.Tensor,\n",
    "    position: tuple[int, int],\n",
    "    visited: set[tuple[int, int]],\n",
    "    Y_test: torch.Tensor,\n",
    "):\n",
    "    rows, cols = answer.shape  # Get the actual number of rows and columns\n",
    "\n",
    "    ind_up = (max(position[0] - 1, 0), position[1])\n",
    "    ind_down = (min(position[0] + 1, rows - 1), position[1])\n",
    "    ind_left = (position[0], max(position[1] - 1, 0))\n",
    "    ind_right = (position[0], min(position[1] + 1, cols - 1))\n",
    "\n",
    "    value_up = answer[ind_up[0]][ind_up[1]] if ind_up not in visited else -1\n",
    "    value_down = answer[ind_down[0]][ind_down[1]] if ind_down not in visited else -1\n",
    "    value_left = answer[ind_left[0]][ind_left[1]] if ind_left not in visited else -1\n",
    "    value_right = answer[ind_right[0]][ind_right[1]] if ind_right not in visited else -1\n",
    "\n",
    "    # Find the maximum value among the neighbours and return the corresponding index\n",
    "    max_value = max(value_up, value_down, value_left, value_right)\n",
    "    if max_value == -1:\n",
    "        return None\n",
    "\n",
    "    if max_value == value_up and Y_test[ind_up[0]][ind_up[1]] != 1.0:\n",
    "        return ind_up\n",
    "    elif max_value == value_down and Y_test[ind_down[0]][ind_down[1]] != 1.0:\n",
    "        return ind_down\n",
    "    elif max_value == value_left and Y_test[ind_left[0]][ind_left[1]] != 1.0:\n",
    "        return ind_left\n",
    "    elif max_value == value_right and Y_test[ind_right[0]][ind_right[1]] != 1.0:\n",
    "        return ind_right\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def evaluate_total_predictions_set(\n",
    "    Y_hat: torch.Tensor, Y_test: torch.Tensor, verbose=True\n",
    "):\n",
    "    preds_: torch.Tensor = torch.zeros(Y_hat.shape[0], dtype=bool)\n",
    "\n",
    "    # Dynamically determine the maze size from the data\n",
    "    rows, cols = (\n",
    "        Y_hat.shape[2],\n",
    "        Y_hat.shape[3],\n",
    "    )  # Assumes Y_hat has shape (batch_size, channels, rows, cols)\n",
    "\n",
    "    wrong_predictions = []  # List to store images of wrong predictions\n",
    "\n",
    "    for index in range(preds_.shape[0]):\n",
    "        preds_[index] = evaluate_found_path(\n",
    "            Y_hat[index].reshape(rows, cols), Y_test[index].numpy().reshape(rows, cols)\n",
    "        )\n",
    "        # Collect wrong predictions\n",
    "        if not preds_[index]:\n",
    "            wrong_predictions.append(Y_hat[index].reshape(rows, cols))\n",
    "\n",
    "    total = preds_.shape[0]\n",
    "    correct = preds_[preds_ == True].shape[0]\n",
    "    correct_percentage = (correct / total) * 100\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n----------MODEL SUMMARY-----------\")\n",
    "        print(\"TOTAL SET SIZE: \", total)\n",
    "        print(\"CORRECT GUESSES: \", correct)\n",
    "        print(\"TOTALING TO ACCURACY%: \", correct_percentage)\n",
    "        print(\"------------------------------------\\n\\n\")\n",
    "\n",
    "    if wrong_predictions:\n",
    "        wrong_predictions_tensor = torch.stack(\n",
    "            wrong_predictions\n",
    "        )  # Stack wrong predictions into a tensor\n",
    "    else:\n",
    "        wrong_predictions_tensor = torch.empty(\n",
    "            0\n",
    "        )  # Return an empty tensor if no wrong predictions\n",
    "\n",
    "    return correct_percentage, preds_, wrong_predictions_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "yHat_test = yHat_test[:1]\n",
    "y_test = y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3., 2., 2., 2., 2., 2., 2., 2., 2., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
       "          [0., 0., 2., 2., 2., 2., 2., 2., 2., 0.],\n",
       "          [0., 0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 2., 0., 3., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 2., 2., 2., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) (8, 6)\n",
      "\n",
      "----------MODEL SUMMARY-----------\n",
      "TOTAL SET SIZE:  1\n",
      "CORRECT GUESSES:  1\n",
      "TOTALING TO ACCURACY%:  100.0\n",
      "------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct_percentage, _, _ = evaluate_total_predictions_set(yHat_test.cpu(), y_test.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Gate (Global Search): (tensor(0, device='cuda:0'), tensor(0, device='cuda:0'))\n",
      "End Gate (Global Search): None\n"
     ]
    }
   ],
   "source": [
    "def find_gate_global(answer: torch.Tensor, threshold: float, start: bool):\n",
    "    rows, cols = answer.shape\n",
    "    gate_candidates = (answer >= threshold).nonzero(as_tuple=True)  # Finde alle Positionen über dem Threshold\n",
    "    if start:\n",
    "        for row, col in zip(*gate_candidates):\n",
    "            if col == 0:  # Starte in der ersten Spalte\n",
    "                return row, col\n",
    "    else:\n",
    "        for row, col in zip(*gate_candidates):\n",
    "            if col == cols - 1:  # Suche in der letzten Spalte\n",
    "                return row, col\n",
    "    return None\n",
    "\n",
    "start = find_gate_global(yHat_test[0, 0], threshold=2.5, start=True)\n",
    "end = find_gate_global(yHat_test[0, 0], threshold=2.5, start=False)\n",
    "\n",
    "print(\"Start Gate (Global Search):\", start)\n",
    "print(\"End Gate (Global Search):\", end)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
