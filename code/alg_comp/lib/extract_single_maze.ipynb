{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path_to_data = \"../data/\"\n",
    "data_size = (50, 50)\n",
    "\n",
    "X_test = np.load(f\"{path_to_data}100000x{data_size[0]}x{data_size[1]}_unsolved.npy\")\n",
    "Y_test = np.load(f\"{path_to_data}100000x{data_size[0]}x{data_size[1]}_solved.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "test_data = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "batchsize = 64\n",
    "# batchsize = test_data.tensors[0].shape[0]\n",
    "test_loader = DataLoader(test_data, batch_size=batchsize, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLevel6Net_10x10(channels=(32, 32, 64, 128, 256, 256), print_shape=False):\n",
    "    class Level6Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Level6Net, self).__init__()\n",
    "\n",
    "            # Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(1, channels[0], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[0], channels[1], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[1], channels[2], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.Conv2d(channels[2], channels[3], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.Conv2d(channels[3], channels[4], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.Conv2d(channels[4], channels[5], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "            )\n",
    "\n",
    "            # Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[5], channels[4], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.ConvTranspose2d(channels[4], channels[3], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.ConvTranspose2d(channels[3], channels[2], kernel_size=2, stride=2, padding=0, output_padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.ConvTranspose2d(channels[2], channels[1], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.ConvTranspose2d(channels[1], channels[0], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.ConvTranspose2d(channels[0], 1, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        def forward(self, x: torch.Tensor):\n",
    "            if print_shape: print(f\"Input shape: {x.shape}\")\n",
    "            x = self.encoder(x)\n",
    "            if print_shape: print(f\"Latent shape: {x.shape}\")\n",
    "            x = self.decoder(x)\n",
    "            if print_shape: print(f\"Output shape: {x.shape}\")\n",
    "            return x\n",
    "\n",
    "    # Instantiate the network\n",
    "    net = Level6Net()\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "    return net, criterion, optimizer\n",
    "\n",
    "def createLevel7Net_20x20(channels=(32, 32, 64, 128, 128, 256, 256), print_shape=False):\n",
    "    class Level7Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Level7Net, self).__init__()\n",
    "\n",
    "            # Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(1, channels[0], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[0], channels[1], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[1], channels[2], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.Conv2d(channels[2], channels[3], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.Conv2d(channels[3], channels[4], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.Conv2d(channels[4], channels[5], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "                nn.Conv2d(channels[5], channels[6], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[6]),\n",
    "            )\n",
    "\n",
    "            # Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[6], channels[5], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "                nn.ConvTranspose2d(channels[5], channels[4], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.ConvTranspose2d(channels[4], channels[3], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.ConvTranspose2d(channels[3], channels[2], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.ConvTranspose2d(channels[2], channels[1], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.ConvTranspose2d(channels[1], channels[0], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.ConvTranspose2d(channels[0], 1, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        def forward(self, x: torch.Tensor):\n",
    "            if print_shape: print(f\"Input shape: {x.shape}\")\n",
    "            x = self.encoder(x)\n",
    "            if print_shape: print(f\"Latent shape: {x.shape}\")\n",
    "            x = self.decoder(x)\n",
    "            if print_shape: print(f\"Output shape: {x.shape}\")\n",
    "            return x\n",
    "\n",
    "    # Instantiate the network\n",
    "    net = Level7Net()\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "    return net, criterion, optimizer\n",
    "\n",
    "def createLevel8Net_30x30(channels=(32, 32, 64, 64, 128, 128, 256, 512), print_shape=False):\n",
    "    class Level8Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Level8Net, self).__init__()\n",
    "\n",
    "            # Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(1, channels[0], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[0], channels[1], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[1], channels[2], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.Conv2d(channels[2], channels[3], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.Conv2d(channels[3], channels[4], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.Conv2d(channels[4], channels[5], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "                nn.Conv2d(channels[5], channels[6], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[6]),\n",
    "                nn.Conv2d(channels[6], channels[7], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[7]),\n",
    "            )\n",
    "\n",
    "            # Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[7], channels[6], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[6]),\n",
    "                nn.ConvTranspose2d(channels[6], channels[5], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "                nn.ConvTranspose2d(channels[5], channels[4], kernel_size=2, stride=2, padding=0, output_padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.ConvTranspose2d(channels[4], channels[3], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.ConvTranspose2d(channels[3], channels[2], kernel_size=2, stride=2, padding=0, output_padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.ConvTranspose2d(channels[2], channels[1], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.ConvTranspose2d(channels[1], channels[0], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.ConvTranspose2d(channels[0], 1, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        def forward(self, x: torch.Tensor):\n",
    "            if print_shape: print(f\"Input shape: {x.shape}\")\n",
    "            x = self.encoder(x)\n",
    "            # if print_shape: print(f\"Latent shape input: {x.shape}\")\n",
    "            # x = self.latent(x)\n",
    "            if print_shape: print(f\"Latent shape: {x.shape}\")\n",
    "            x = self.decoder(x)\n",
    "            if print_shape: print(f\"Output shape: {x.shape}\")\n",
    "            return x\n",
    "\n",
    "    # Instantiate the network\n",
    "    net = Level8Net()\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "    return net, criterion, optimizer\n",
    "\n",
    "def createLevel8Net_40x40(channels=(32, 32, 64, 64, 128, 128, 256, 512), print_shape=False):\n",
    "    class Level8Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Level8Net, self).__init__()\n",
    "\n",
    "            # Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(1, channels[0], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[0], channels[1], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[1], channels[2], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.Conv2d(channels[2], channels[3], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.Conv2d(channels[3], channels[4], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.Conv2d(channels[4], channels[5], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "                nn.Conv2d(channels[5], channels[6], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[6]),\n",
    "                nn.Conv2d(channels[6], channels[7], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[7]),\n",
    "            )\n",
    "\n",
    "            # Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[7], channels[6], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[6]),\n",
    "                nn.ConvTranspose2d(channels[6], channels[5], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "                nn.ConvTranspose2d(channels[5], channels[4], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.ConvTranspose2d(channels[4], channels[3], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.ConvTranspose2d(channels[3], channels[2], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.ConvTranspose2d(channels[2], channels[1], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.ConvTranspose2d(channels[1], channels[0], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.ConvTranspose2d(channels[0], 1, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        def forward(self, x: torch.Tensor):\n",
    "            if print_shape: print(f\"Input shape: {x.shape}\")\n",
    "            x = self.encoder(x)\n",
    "            # if print_shape: print(f\"Latent shape input: {x.shape}\")\n",
    "            # x = self.latent(x)\n",
    "            if print_shape: print(f\"Latent shape: {x.shape}\")\n",
    "            x = self.decoder(x)\n",
    "            if print_shape: print(f\"Output shape: {x.shape}\")\n",
    "            return x\n",
    "\n",
    "    # Instantiate the network\n",
    "    net = Level8Net()\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "    return net, criterion, optimizer\n",
    "\n",
    "def createLevel8Net_50x50(channels=(32, 32, 64, 64, 128, 128, 256, 512), print_shape=False):\n",
    "    class Level8Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Level8Net, self).__init__()\n",
    "\n",
    "            # Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(1, channels[0], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[0], channels[1], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(channels[1], channels[2], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.Conv2d(channels[2], channels[3], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.Conv2d(channels[3], channels[4], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.Conv2d(channels[4], channels[5], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "                nn.Conv2d(channels[5], channels[6], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[6]),\n",
    "                nn.Conv2d(channels[6], channels[7], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[7]),\n",
    "            )\n",
    "\n",
    "            # Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[7], channels[6], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[6]),\n",
    "                nn.ConvTranspose2d(channels[6], channels[5], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[5]),\n",
    "                nn.ConvTranspose2d(channels[5], channels[4], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[4]),\n",
    "                nn.ConvTranspose2d(channels[4], channels[3], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[3]),\n",
    "                nn.ConvTranspose2d(channels[3], channels[2], kernel_size=2, stride=2, padding=0, output_padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[2]),\n",
    "                nn.ConvTranspose2d(channels[2], channels[1], kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[1]),\n",
    "                nn.ConvTranspose2d(channels[1], channels[0], kernel_size=2, stride=2, padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(channels[0]),\n",
    "                nn.ConvTranspose2d(channels[0], 1, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        def forward(self, x: torch.Tensor):\n",
    "            if print_shape: print(f\"Input shape: {x.shape}\")\n",
    "            x = self.encoder(x)\n",
    "            # if print_shape: print(f\"Latent shape input: {x.shape}\")\n",
    "            # x = self.latent(x)\n",
    "            if print_shape: print(f\"Latent shape: {x.shape}\")\n",
    "            x = self.decoder(x)\n",
    "            if print_shape: print(f\"Output shape: {x.shape}\")\n",
    "            return x\n",
    "\n",
    "    # Instantiate the network\n",
    "    net = Level8Net()\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "    return net, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, _, _ = createLevel8Net_30x30()\n",
    "\n",
    "net.load_state_dict(\n",
    "    torch.load(\n",
    "        \"../archive/Level8Net_30x30_89.8200/net.pt\",\n",
    "        weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of data\n",
    "X, y = next(iter(test_loader))\n",
    "\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "# net.eval()\n",
    "net.to(device)\n",
    "\n",
    "# Get the network's prediction\n",
    "y_hat = net(X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_no = 34 # 1, 6, 15, 19\n",
    "# image_no = 4 # 2, 4\n",
    "# size 20: 4\n",
    "# size 10: 1\n",
    "# 44\n",
    "# docker cp frosty_rubin:/root/code/PlotNeuralNet/models/10xFCAE.pdf C:\\Uni\\Repository\\WiSe24\\bachelor\\report\\images/10xFCAE.pdf\n",
    "# docker cp frosty_rubin:/root/code/PlotNeuralNet/models/10xFCAE.pdf C:\\Uni\\Repository\\WiSe24\\bachelor\\report\\images/10xFCAE.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"338.4pt\" height=\"338.4pt\" viewBox=\"0 0 338.4 338.4\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-01-31T10:03:53.870648</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 338.4 \n",
       "L 338.4 338.4 \n",
       "L 338.4 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#pee8a2b70cb)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image31ce68d320\" transform=\"scale(1 -1) translate(0 -324)\" x=\"7.2\" y=\"-7.2\" width=\"324\" height=\"324\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pee8a2b70cb\">\n",
       "   <rect x=\"7.2\" y=\"7.2\" width=\"324\" height=\"324\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch.round(X.squeeze()[image_no].detach().cpu()).numpy(), cmap=\"cividis\")\n",
    "# plt.imshow(y.squeeze()[image_no].detach().cpu().numpy(), cmap=\"viridis\")\n",
    "plt.axis(\"off\")\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./{data_size[0]}xUnsolved.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"338.4pt\" height=\"338.4pt\" viewBox=\"0 0 338.4 338.4\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-01-31T10:03:54.005372</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 338.4 \n",
       "L 338.4 338.4 \n",
       "L 338.4 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p56490aaaa1)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image4d3b255fa0\" transform=\"scale(1 -1) translate(0 -324)\" x=\"7.2\" y=\"-7.2\" width=\"324\" height=\"324\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p56490aaaa1\">\n",
       "   <rect x=\"7.2\" y=\"7.2\" width=\"324\" height=\"324\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.squeeze()[image_no].detach().cpu().numpy(), cmap=\"cividis\")\n",
    "plt.axis(\"off\")\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./{data_size[0]}xSolved.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20), frameon=False) # frameon=False solved it\n",
    "# ax = plt.gca()\n",
    "# ax.imshow(X.squeeze()[4].detach().cpu().numpy(), cmap=\"viridis\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
